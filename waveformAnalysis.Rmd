### Packages

```{r,  results='hide', error=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(umap)
library(seewave)
library(tuneR)
library(phonTools)
library(signal)
library(warbleR)
library(voice)
library(randomForest)
library(datasets)
library(caret)

```

# Part 1: Waveform Analysis

### read in files and convert into Wave class type
```{r}
filenames <- list.files("150data", pattern="*.wav", full.names=TRUE)
ldf <- lapply(filenames, tuneR::readWave)

```

### Spectrogram of a closed hi-hat.
```{r}
hat <- ldf[[3]]
seewave::spectro(hat, f=48000, flog=TRUE, flim=c(0,20), tlim=c(0,0.2), main='hat')
```
### Spectrogram of a snare drum.
```{r}
snare <- ldf[[115]]
seewave::spectro(snare, f=48000, flog=TRUE, flim=c(0,20), tlim=c(0,0.2), main='snare')
```
### Spectrogram of a kick drum.
```{r}
kick <- ldf[[51]]
seewave::spectro(kick, f=48000, flog=TRUE, flim=c(0,20), tlim=c(0,0.2), main='kick')
```
### above are just three examples. Different samples end up getting very hard to tell apart. In this case, the snare spectrogram looks very similar to this kick drum's spectrogram:
```{r}
snare2 <- ldf[[101]]
kick2 <- ldf[[52]]
seewave::spectro(snare2, f=48000, flog=TRUE, flim=c(0,20), tlim=c(0,0.2), main='snare2')
seewave::spectro(kick2, f=48000, flog=TRUE, flim=c(0,20), tlim=c(0,0.2), main='kick2')
```

### Compare dominant frequencies over time of three instrument samples
```{r, error=FALSE, warning=FALSE}
hatDfreq <- data.frame(seewave::dfreq(ldf[[2]], plot=FALSE, tlim=c(0,0.2), flim=c(0,20)))
snareDfreq <- data.frame(seewave::dfreq(ldf[[115]], plot=FALSE, tlim=c(0,0.2), flim=c(0,20)))
kickDfreq <- data.frame(seewave::dfreq(ldf[[51]], plot=FALSE, tlim=c(0,0.2), flim=c(0,20)))

hatDfreq$instrument <- "Hat"
snareDfreq$instrument <- "Snare"
kickDfreq$instrument <- "Kick"
combined_df <- rbind(hatDfreq, snareDfreq, kickDfreq)

ggplot(data = combined_df, aes(x = x, y = y, color = instrument)) +
  geom_line() +
  scale_y_log10() +
  labs(title = "Dominant frequencies Hat, Snare, and Kick") +
  xlab("Time (s)") +
  ylab("Frequency (kHz)")
```
# Part 2: Organizing/Tidying Data


### go through training/testing data and add each file to a class based on its filename
```{r,  results='hide', error=FALSE, warning=FALSE}
# Function to trim strings based on substrings
trim_to_instrument <- function(string) {
  if (grepl("snare", string, ignore.case = TRUE)) {
    return("snare")
  } else if (grepl("hihat", string, ignore.case = TRUE)) {
    return("hat")
  } else if (grepl("kick", string, ignore.case = TRUE)) {
    return("kick")
  } else {
    stop("Error: No match found for instrument in string '", string, "'")
  }
}

class_list <- sapply(filenames, trim_to_instrument)
class_list <- factor(class_list)
class_list

```

### hand-crafted features
``` {r,  results='hide', error=FALSE, warning=FALSE}
#medians of amplitude envelopes
medians <- sapply(ldf, seewave::M, simplify = TRUE)

#dominant frequencies each wave
Dfreq <- lapply(ldf, seewave::dfreq, plot=FALSE)
maxes <- as.data.frame(Dfreq) %>% select(-starts_with("x"))
maxes <-sapply(maxes, function(x) max(x, na.rm = TRUE), simplify = TRUE)

#spectral flatnesses
specs <- lapply(ldf, spec, plot=FALSE)
sfms <- sapply(specs, sfm, simplify = TRUE)

#mfccs
M1 <- extract_features(filenames, 
  features = c("mfcc"), 
  check.mono=FALSE, 
  windowShift = 20,
  numcep = 4)
mfccs <- subset(M1, section_seq_file == 1)
mfccdf <- mfccs[, -c(1:3)]
```

### combine into single dataframe
```{r}
data <- data.frame(medians, maxes, sfms, class_list)
rownames(data) <- NULL
df <- cbind(data, mfccdf)
df
```

### convert class list into factor variable, check with frequency table, separate into test and training data
```{r}
df$class_list <- as.factor(df$class_list)
table(df$class_list)

#set.seed(222)
ind <- sample(2, nrow(df), replace = TRUE, prob = c(0.7, 0.3))
train <- df[ind==1,]
test <- df[ind==2,]
```
# Part 3: Training Random Forest Classifier

### create the random forest using the R randomForest package:
```{r}
rf <- randomForest(class_list~., data=train, proximity=TRUE, ntree=150)
print(rf)

```

### Use newly created random forest to classify its own training data. Resulting accuracy should be 100%
```{r}
p1 <- predict(rf, train)
confusionMatrix(p1, train$ class_list)

```

### classify test data and generate confusion matrix
```{r}
p2 <- predict(rf, test)
confusionMatrix(p2, test$ class_list)
```

### randomForest's tuneRF function to explore different ntree values
```{r}

#### played around with this function a little bit, it didn't seem to be very helpful given that the tuning method has no patience for anything besides an decrease in error: 
t <- tuneRF(train[,-4], train[,4],
       stepFactor = 5,
       plot = TRUE,
       ntreeTry = 50,
       trace = TRUE,
       doBest=TRUE,
       improve = 0.01)



p3 <- predict(t, test)
confusionMatrix(p3, test$ class_list)
```



# Part 4: Classifier Analysis

### graph is pretty self explanatory
```{r}
hist(treesize(rf),
     main = "No. of Nodes for the Trees",
     col = "green")
```
### error rate of random forest
```{r}
plot(rf)
```
### mfcc2 is the most important attribute followed by mfcc1
```{r}
varImpPlot(rf, n.var = 7,main = "Variable Importance")
importance(rf)
```
### Partial dependence plot gives a graphical depiction of the marginal effect of a variable on the class probability (classification)
```{r}
partialPlot(rf, train, sfms, "kick")
```
#### if the sfm is less than ~0.3, higher chances of classifying into kick class.


### Plot the scaling coordinates of the proximity matrix from randomForest
```{r}
MDSplot(rf, train$class_list)
```